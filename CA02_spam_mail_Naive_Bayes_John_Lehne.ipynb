{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02-spam-mail-Naive-Bayes-John_Lehne.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code is for an email spam classifier that uses Naive Bayes supervised machine learning algorithm to fulfill this function"
      ],
      "metadata": {
        "id": "MvV4W0V_XWmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary packages\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Z5wwwpziXog3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will build a dictionary of the most common 3000 words from the email content\n",
        "\n",
        "def create_dict(files):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(files,x) for x in os.listdir(files)]\n",
        "  for message in emails:\n",
        "    with open(message) as m:\n",
        "      for content in m:\n",
        "        text = content.split()\n",
        "        all_words += text\n",
        "# First all symbols and words are added to the dictionary\n",
        "\n",
        "  dictionary = Counter(all_words)\n",
        "  words_removing = list(dictionary)\n",
        "\n",
        "  for word in words_removing:\n",
        "    if word.isalpha() == False:\n",
        "      del dictionary[word]\n",
        "    elif len(word) == 1:\n",
        "      del dictionary[word]\n",
        "# Then removes all non-alpha-numeric and any single-alpha-numeric characters\n",
        "\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "# Then the dictionary is shrunk by keeping only 3000 most common words\n",
        "\n",
        "  return(dictionary)\n",
        "# Final step is returning the dictionary"
      ],
      "metadata": {
        "id": "aYxAP0D3aY7-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This extracts feature columns and populate their values\n",
        "# A feature matrix of 3000 columns and rows equal to the number of email files\n",
        "\n",
        "def extricate_features(message_dir):\n",
        "  data_files = [os.path.join(message_dir, y) for y in os.listdir(message_dir)]\n",
        "  feature_matrix = np.zeros((len(data_files),3000))\n",
        "  column_labels = np.zeros(len(data_files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for dat_fil in data_files:\n",
        "    with open(dat_fil) as dat:\n",
        "      for fil, content in enumerate(dat):\n",
        "        if fil == 2:\n",
        "          text = content.split()\n",
        "          for term in text:\n",
        "            termID = 0\n",
        "            for fil, d in enumerate(dictionary):\n",
        "              if d[0] == term:\n",
        "                termID = fil\n",
        "                feature_matrix[docID, termID] = text.count(term)\n",
        "      column_labels[docID] = 0;\n",
        "      filepathTokens = dat_fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        column_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return feature_matrix, column_labels\n",
        "\n",
        "# This function uses the file name to determine if an email is spam or not\n",
        "# This function also extracts the training and testing datasets and returns Feature Dataset and Label column\n"
      ],
      "metadata": {
        "id": "aMirvaBmk65c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the beginning of the main program\n",
        "# This calls on the previous two functions which will need to be run first\n",
        "\n",
        "TRAIN_DIR = '/content/drive/MyDrive/BSAN 6070/CA02/train-mails'\n",
        "TEST_DIR = '/content/drive/MyDrive/BSAN 6070/CA02/test-mails'"
      ],
      "metadata": {
        "id": "Lv4CcM5Cmt1K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = create_dict(TRAIN_DIR)\n",
        "# Creating a dictionary using the the previously defined function\n",
        "\n",
        "print(\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extricate_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extricate_features(TEST_DIR)\n",
        "# Creating a features matrix and labels using the previously defined function\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "print(\"Training Model using Gaussian Naive Bayes algorithm\")\n",
        "model.fit(features_matrix, labels)\n",
        "# The model has been trained using model.fit() and Training Dataset\n",
        "print(\"Training Completed\")\n",
        "print(\"Testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "# Test Data is scored by running the Trained Model with the Test Dataset\n",
        "print(\"Completed classification of the Test Data ... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print(accuracy_score(test_labels, predicted_labels))\n",
        "# Model performance is printed in terms of an Accuracy Score\n",
        "\n",
        "## End of Program ##\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU7R79qJIQBo",
        "outputId": "a8241e7d-6f9e-4daf-fa4e-02cae43de2cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naive Bayes algorithm\n",
            "Training Completed\n",
            "Testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data ... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ]
        }
      ]
    }
  ]
}